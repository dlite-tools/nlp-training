{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpiper\n",
    "import torch\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint\n",
    ")\n",
    "\n",
    "from inference.architectures.text_classification import BaselineModel\n",
    "from inference.data_processors.processor import Processor\n",
    "from inference.data_processors.transformers.preprocessing import (\n",
    "    NLPiperIntegration,\n",
    "    VocabTransform,\n",
    ")\n",
    "from training.data_augmentation import SentenceAugmentation\n",
    "from training.trainer import TextClassificationTrainer\n",
    "from training.datasets.text_classification import AGNewsDataModule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%md\n"
    }
   },
   "source": [
    "## Hyper-parameters and other Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "NUMBER_CLASSES = 4\n",
    "EMBED_DIM = 100\n",
    "N_EPOCHS = 5\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"valid_loss\", mode=\"min\", save_weights_only=True)\n",
    "early_stop_callback = EarlyStopping(monitor=\"valid_loss\", mode=\"min\", patience=4)\n",
    "mf_logger = MLFlowLogger(\n",
    "    experiment_name=\"AG News - Text Classification\",\n",
    "    run_name=\"Baseline\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%md\n"
    }
   },
   "source": [
    "## Data transformation pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocab = VocabTransform()\n",
    "preprocessing = [\n",
    "    SentenceAugmentation(),\n",
    "    NLPiperIntegration(pipeline=nlpiper.core.Compose([\n",
    "        nlpiper.transformers.cleaners.CleanPunctuation(),\n",
    "        nlpiper.transformers.tokenizers.MosesTokenizer()\n",
    "    ])),\n",
    "    vocab\n",
    "]\n",
    "\n",
    "processor = Processor(preprocessing=preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%md\n"
    }
   },
   "source": [
    "## Setup data module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building the Vocab.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [01:19<00:00, 1508.09it/s]\n"
     ]
    }
   ],
   "source": [
    "data_module = AGNewsDataModule(processor=processor)\n",
    "\n",
    "vocab.build_vocab(processor, AG_NEWS(split='train'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%md\n"
    }
   },
   "source": [
    "## Model and Model Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = BaselineModel(vocab_size=len(vocab), embed_dim=EMBED_DIM, num_class=NUMBER_CLASSES)\n",
    "\n",
    "model_trainer = TextClassificationTrainer(\n",
    "    model=model,\n",
    "    num_class=NUMBER_CLASSES\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    callbacks=[model_checkpoint, early_stop_callback],\n",
    "    max_epochs=N_EPOCHS,\n",
    "    logger=mf_logger,\n",
    "    gpus=torch.cuda.device_count(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%md\n"
    }
   },
   "source": [
    "## Training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "trainer.fit(model_trainer, data_module)\n",
    "trainer.test(datamodule=data_module)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}